{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "This notebook should include preliminary and baseline modeling.\n",
    "- Try as many different models as possible.\n",
    "- Don't worry about hyperparameter tuning or cross validation here.\n",
    "- Ideas include:\n",
    "    - linear regression\n",
    "    - support vector machines\n",
    "    - random forest\n",
    "    - xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import models and fit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.220000e+03</td>\n",
       "      <td>5.220000e+03</td>\n",
       "      <td>5.220000e+03</td>\n",
       "      <td>5.220000e+03</td>\n",
       "      <td>5.220000e+03</td>\n",
       "      <td>5.220000e+03</td>\n",
       "      <td>5.220000e+03</td>\n",
       "      <td>5.220000e+03</td>\n",
       "      <td>5.220000e+03</td>\n",
       "      <td>5.220000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>5.220000e+03</td>\n",
       "      <td>5.220000e+03</td>\n",
       "      <td>5.220000e+03</td>\n",
       "      <td>5.220000e+03</td>\n",
       "      <td>5.220000e+03</td>\n",
       "      <td>5.220000e+03</td>\n",
       "      <td>5220.0</td>\n",
       "      <td>5.220000e+03</td>\n",
       "      <td>5.220000e+03</td>\n",
       "      <td>5.220000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.770981e-15</td>\n",
       "      <td>-1.090316e-15</td>\n",
       "      <td>3.062684e-17</td>\n",
       "      <td>-2.885729e-14</td>\n",
       "      <td>-4.764175e-17</td>\n",
       "      <td>5.444772e-18</td>\n",
       "      <td>-2.205133e-16</td>\n",
       "      <td>2.109849e-16</td>\n",
       "      <td>2.552237e-17</td>\n",
       "      <td>-3.266863e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.266863e-17</td>\n",
       "      <td>4.628056e-17</td>\n",
       "      <td>1.088954e-17</td>\n",
       "      <td>1.211462e-16</td>\n",
       "      <td>6.805965e-18</td>\n",
       "      <td>2.586267e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.167158e-18</td>\n",
       "      <td>-2.463759e-16</td>\n",
       "      <td>-6.125368e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000096e+00</td>\n",
       "      <td>1.000096e+00</td>\n",
       "      <td>1.000096e+00</td>\n",
       "      <td>1.000096e+00</td>\n",
       "      <td>1.000096e+00</td>\n",
       "      <td>1.000096e+00</td>\n",
       "      <td>1.000096e+00</td>\n",
       "      <td>1.000096e+00</td>\n",
       "      <td>1.000096e+00</td>\n",
       "      <td>1.000096e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000096e+00</td>\n",
       "      <td>1.000096e+00</td>\n",
       "      <td>1.000096e+00</td>\n",
       "      <td>1.000096e+00</td>\n",
       "      <td>1.000096e+00</td>\n",
       "      <td>1.000096e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000096e+00</td>\n",
       "      <td>1.000096e+00</td>\n",
       "      <td>1.000096e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.425031e+01</td>\n",
       "      <td>-3.984160e+00</td>\n",
       "      <td>-2.327139e-01</td>\n",
       "      <td>-3.856430e+00</td>\n",
       "      <td>-5.948834e-01</td>\n",
       "      <td>-3.879067e-01</td>\n",
       "      <td>-1.860708e+00</td>\n",
       "      <td>-1.815390e+00</td>\n",
       "      <td>-8.734723e-01</td>\n",
       "      <td>-1.298806e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.368281e-02</td>\n",
       "      <td>-8.897520e-02</td>\n",
       "      <td>-3.333333e-01</td>\n",
       "      <td>-1.964670e-01</td>\n",
       "      <td>-1.467188e-01</td>\n",
       "      <td>-2.861211e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.937088e-02</td>\n",
       "      <td>-1.440210e+00</td>\n",
       "      <td>-2.865127e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-2.741189e-01</td>\n",
       "      <td>-6.221657e-01</td>\n",
       "      <td>-2.327139e-01</td>\n",
       "      <td>9.497093e-03</td>\n",
       "      <td>-5.948834e-01</td>\n",
       "      <td>-2.787560e-01</td>\n",
       "      <td>-6.563103e-01</td>\n",
       "      <td>-9.490220e-01</td>\n",
       "      <td>-8.734723e-01</td>\n",
       "      <td>-2.383075e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.368281e-02</td>\n",
       "      <td>-8.897520e-02</td>\n",
       "      <td>-3.333333e-01</td>\n",
       "      <td>-1.964670e-01</td>\n",
       "      <td>-1.467188e-01</td>\n",
       "      <td>-2.861211e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.937088e-02</td>\n",
       "      <td>-1.440210e+00</td>\n",
       "      <td>-2.865127e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.190130e-01</td>\n",
       "      <td>1.536791e-01</td>\n",
       "      <td>-2.327139e-01</td>\n",
       "      <td>3.885095e-01</td>\n",
       "      <td>-5.948834e-01</td>\n",
       "      <td>-2.162251e-01</td>\n",
       "      <td>-2.361085e-01</td>\n",
       "      <td>-8.265354e-02</td>\n",
       "      <td>2.685541e-03</td>\n",
       "      <td>-2.383075e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.368281e-02</td>\n",
       "      <td>-8.897520e-02</td>\n",
       "      <td>-3.333333e-01</td>\n",
       "      <td>-1.964670e-01</td>\n",
       "      <td>-1.467188e-01</td>\n",
       "      <td>-2.861211e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.937088e-02</td>\n",
       "      <td>6.943432e-01</td>\n",
       "      <td>-2.865127e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.046290e-01</td>\n",
       "      <td>7.858490e-01</td>\n",
       "      <td>-2.327139e-01</td>\n",
       "      <td>5.401145e-01</td>\n",
       "      <td>1.264573e+00</td>\n",
       "      <td>-1.122035e-01</td>\n",
       "      <td>3.394031e-01</td>\n",
       "      <td>7.837149e-01</td>\n",
       "      <td>8.788434e-01</td>\n",
       "      <td>8.221913e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.368281e-02</td>\n",
       "      <td>-8.897520e-02</td>\n",
       "      <td>-3.333333e-01</td>\n",
       "      <td>-1.964670e-01</td>\n",
       "      <td>-1.467188e-01</td>\n",
       "      <td>-2.861211e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.937088e-02</td>\n",
       "      <td>6.943432e-01</td>\n",
       "      <td>-2.865127e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.151980e+00</td>\n",
       "      <td>1.619164e+00</td>\n",
       "      <td>6.110714e+00</td>\n",
       "      <td>6.917195e-01</td>\n",
       "      <td>8.702396e+00</td>\n",
       "      <td>1.577452e+01</td>\n",
       "      <td>6.517127e+00</td>\n",
       "      <td>5.115557e+00</td>\n",
       "      <td>8.764264e+00</td>\n",
       "      <td>9.306182e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.862794e+01</td>\n",
       "      <td>1.123909e+01</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>5.089913e+00</td>\n",
       "      <td>6.815757e+00</td>\n",
       "      <td>3.495024e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.441527e+01</td>\n",
       "      <td>6.943432e-01</td>\n",
       "      <td>3.490246e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1             2             3             4  \\\n",
       "count  5.220000e+03  5.220000e+03  5.220000e+03  5.220000e+03  5.220000e+03   \n",
       "mean   4.770981e-15 -1.090316e-15  3.062684e-17 -2.885729e-14 -4.764175e-17   \n",
       "std    1.000096e+00  1.000096e+00  1.000096e+00  1.000096e+00  1.000096e+00   \n",
       "min   -2.425031e+01 -3.984160e+00 -2.327139e-01 -3.856430e+00 -5.948834e-01   \n",
       "25%   -2.741189e-01 -6.221657e-01 -2.327139e-01  9.497093e-03 -5.948834e-01   \n",
       "50%    2.190130e-01  1.536791e-01 -2.327139e-01  3.885095e-01 -5.948834e-01   \n",
       "75%    5.046290e-01  7.858490e-01 -2.327139e-01  5.401145e-01  1.264573e+00   \n",
       "max    1.151980e+00  1.619164e+00  6.110714e+00  6.917195e-01  8.702396e+00   \n",
       "\n",
       "                  5             6             7             8             9  \\\n",
       "count  5.220000e+03  5.220000e+03  5.220000e+03  5.220000e+03  5.220000e+03   \n",
       "mean   5.444772e-18 -2.205133e-16  2.109849e-16  2.552237e-17 -3.266863e-17   \n",
       "std    1.000096e+00  1.000096e+00  1.000096e+00  1.000096e+00  1.000096e+00   \n",
       "min   -3.879067e-01 -1.860708e+00 -1.815390e+00 -8.734723e-01 -1.298806e+00   \n",
       "25%   -2.787560e-01 -6.563103e-01 -9.490220e-01 -8.734723e-01 -2.383075e-01   \n",
       "50%   -2.162251e-01 -2.361085e-01 -8.265354e-02  2.685541e-03 -2.383075e-01   \n",
       "75%   -1.122035e-01  3.394031e-01  7.837149e-01  8.788434e-01  8.221913e-01   \n",
       "max    1.577452e+01  6.517127e+00  5.115557e+00  8.764264e+00  9.306182e+00   \n",
       "\n",
       "       ...            36            37            38            39  \\\n",
       "count  ...  5.220000e+03  5.220000e+03  5.220000e+03  5.220000e+03   \n",
       "mean   ... -3.266863e-17  4.628056e-17  1.088954e-17  1.211462e-16   \n",
       "std    ...  1.000096e+00  1.000096e+00  1.000096e+00  1.000096e+00   \n",
       "min    ... -5.368281e-02 -8.897520e-02 -3.333333e-01 -1.964670e-01   \n",
       "25%    ... -5.368281e-02 -8.897520e-02 -3.333333e-01 -1.964670e-01   \n",
       "50%    ... -5.368281e-02 -8.897520e-02 -3.333333e-01 -1.964670e-01   \n",
       "75%    ... -5.368281e-02 -8.897520e-02 -3.333333e-01 -1.964670e-01   \n",
       "max    ...  1.862794e+01  1.123909e+01  3.000000e+00  5.089913e+00   \n",
       "\n",
       "                 40            41      42            43            44  \\\n",
       "count  5.220000e+03  5.220000e+03  5220.0  5.220000e+03  5.220000e+03   \n",
       "mean   6.805965e-18  2.586267e-17     0.0  8.167158e-18 -2.463759e-16   \n",
       "std    1.000096e+00  1.000096e+00     0.0  1.000096e+00  1.000096e+00   \n",
       "min   -1.467188e-01 -2.861211e-01     0.0 -6.937088e-02 -1.440210e+00   \n",
       "25%   -1.467188e-01 -2.861211e-01     0.0 -6.937088e-02 -1.440210e+00   \n",
       "50%   -1.467188e-01 -2.861211e-01     0.0 -6.937088e-02  6.943432e-01   \n",
       "75%   -1.467188e-01 -2.861211e-01     0.0 -6.937088e-02  6.943432e-01   \n",
       "max    6.815757e+00  3.495024e+00     0.0  1.441527e+01  6.943432e-01   \n",
       "\n",
       "                 45  \n",
       "count  5.220000e+03  \n",
       "mean  -6.125368e-17  \n",
       "std    1.000096e+00  \n",
       "min   -2.865127e-01  \n",
       "25%   -2.865127e-01  \n",
       "50%   -2.865127e-01  \n",
       "75%   -2.865127e-01  \n",
       "max    3.490246e+00  \n",
       "\n",
       "[8 rows x 46 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "X_train_scaled = pd.read_csv('../data/processed/X_train_scaled.csv')\n",
    "X_test_scaled = pd.read_csv('../data/processed/X_test_scaled.csv')\n",
    "y_train = pd.read_csv('../data/processed/y_train.csv')\n",
    "y_test = pd.read_csv('../data/processed/y_test.csv')\n",
    "\n",
    "X_train_scaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: \t 3479895584.8480883\n",
      "Test MSE: \t 4328005232.184329\n",
      "Train R2: \t 0.965973443727785\n",
      "Test R2: \t 0.961626506100333\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "LR_model = LinearRegression()\n",
    "LR_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_train_LR = LR_model.predict(X_train_scaled)\n",
    "y_test_LR = LR_model.predict(X_test_scaled)\n",
    "\n",
    "train_mse_LR = mean_squared_error(y_train, y_train_LR)\n",
    "train_r2_LR = r2_score(y_train, y_train_LR)\n",
    "\n",
    "mse_LR = mean_squared_error(y_test, y_test_LR)\n",
    "r2_LR = r2_score(y_test, y_test_LR)\n",
    "\n",
    "LR_metrics = {'MSE':mse_LR, 'R2':r2_LR}\n",
    "\n",
    "print(f'Train MSE: \\t {train_mse_LR}')\n",
    "print(f'Test MSE: \\t {mse_LR}')\n",
    "print(f'Train R2: \\t {train_r2_LR}')\n",
    "print(f'Test R2: \\t {r2_LR}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: \t 0.0\n",
      "Test MSE: \t 77004555.55555555\n",
      "Train R2: \t 1.0\n",
      "Test R2: \t 0.9993172527101206\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "tree_model = DecisionTreeRegressor(random_state=42)\n",
    "tree_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_train_tree = tree_model.predict(X_train_scaled)\n",
    "y_test_tree = tree_model.predict(X_test_scaled)\n",
    "\n",
    "train_mse_tree = mean_squared_error(y_train, y_train_tree)\n",
    "train_r2_tree = r2_score(y_train, y_train_tree)\n",
    "\n",
    "mse_tree = mean_squared_error(y_test, y_test_tree)\n",
    "r2_tree = r2_score(y_test, y_test_tree)\n",
    "\n",
    "DTree_metrics = {'MSE':mse_tree, 'R2':r2_tree}\n",
    "\n",
    "print(f'Train MSE: \\t {train_mse_tree}')\n",
    "print(f'Test MSE: \\t {mse_tree}')\n",
    "print(f'Train R2: \\t {train_r2_tree}')\n",
    "print(f'Test R2: \\t {r2_tree}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kool3\\anaconda3\\envs\\Lighthouse\\lib\\site-packages\\sklearn\\base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: \t 7239159.801686489\n",
      "Test MSE: \t 75306351.56509332\n",
      "Train R2: \t 0.9999292152099539\n",
      "Test R2: \t 0.9993323095358342\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "forest_model = RandomForestRegressor(random_state=42)\n",
    "forest_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_train_forest = forest_model.predict(X_train_scaled)\n",
    "y_test_forest = forest_model.predict(X_test_scaled)\n",
    "\n",
    "train_mse_forest = mean_squared_error(y_train, y_train_forest)\n",
    "train_r2_forest = r2_score(y_train, y_train_forest)\n",
    "\n",
    "mse_forest = mean_squared_error(y_test, y_test_forest)\n",
    "r2_forest = r2_score(y_test, y_test_forest)\n",
    "\n",
    "Forest_metrics = {'MSE':mse_forest, 'R2':r2_forest}\n",
    "\n",
    "print(f'Train MSE: \\t {train_mse_forest}')\n",
    "print(f'Test MSE: \\t {mse_forest}')\n",
    "print(f'Train R2: \\t {train_r2_forest}')\n",
    "print(f'Test R2: \\t {r2_forest}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kool3\\anaconda3\\envs\\Lighthouse\\lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: \t 106808398328.74374\n",
      "Test MSE: \t 118773156180.84033\n",
      "Train R2: \t 1.0\n",
      "Test R2: \t -0.05308120938878913\n"
     ]
    }
   ],
   "source": [
    "# SVR\n",
    "svr_model = SVR(kernel='rbf')\n",
    "svr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_train_svr = svr_model.predict(X_train_scaled)\n",
    "y_test_svr = svr_model.predict(X_test_scaled)\n",
    "\n",
    "train_mse_svr = mean_squared_error(y_train, y_train_svr)\n",
    "train_r2_svr = r2_score(y_train, y_train_tree)\n",
    "\n",
    "mse_svr = mean_squared_error(y_test, y_test_svr)\n",
    "r2_svr = r2_score(y_test, y_test_svr)\n",
    "\n",
    "SVR_metrics = {'MSE':mse_svr, 'R2':r2_svr}\n",
    "\n",
    "print(f'Train MSE: \\t {train_mse_svr}')\n",
    "print(f'Test MSE: \\t {mse_svr}')\n",
    "print(f'Train R2: \\t {train_r2_svr}')\n",
    "print(f'Test R2: \\t {r2_svr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: \t 4386703.237700574\n",
      "Test MSE: \t 29075644.353282813\n",
      "Train R2: \t 0.9999571066427346\n",
      "Test R2: \t 0.999742205935214\n"
     ]
    }
   ],
   "source": [
    "# XGBoots\n",
    "xgb_model = XGBRegressor(random_state=42)\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_train_xgb = xgb_model.predict(X_train_scaled)\n",
    "y_test_xgb = xgb_model.predict(X_test_scaled)\n",
    "\n",
    "train_mse_xgb = mean_squared_error(y_train, y_train_xgb)\n",
    "train_r2_xgb = r2_score(y_train, y_train_xgb)\n",
    "\n",
    "mse_xgb = mean_squared_error(y_test, y_test_xgb)\n",
    "r2_xgb = r2_score(y_test, y_test_xgb)\n",
    "\n",
    "XGB_metrics = {'MSE':mse_xgb, 'R2':r2_xgb}\n",
    "\n",
    "print(f'Train MSE: \\t {train_mse_xgb}')\n",
    "print(f'Test MSE: \\t {mse_xgb}')\n",
    "print(f'Train R2: \\t {train_r2_xgb}')\n",
    "print(f'Test R2: \\t {r2_xgb}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider what metrics you want to use to evaluate success.\n",
    "- If you think about mean squared error, can we actually relate to the amount of error?\n",
    "- Try root mean squared error so that error is closer to the original units (dollars)\n",
    "- What does RMSE do to outliers?\n",
    "- Is mean absolute error a good metric for this problem?\n",
    "- What about R^2? Adjusted R^2?\n",
    "- Briefly describe your reasons for picking the metrics you use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>4328005232.18433</td>\n",
       "      <td>65787.57658</td>\n",
       "      <td>0.96163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>77004555.55556</td>\n",
       "      <td>8775.22396</td>\n",
       "      <td>0.99932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>75306351.56509</td>\n",
       "      <td>8677.92323</td>\n",
       "      <td>0.99933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>118773156180.84033</td>\n",
       "      <td>344634.81568</td>\n",
       "      <td>-0.05308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>29075644.35328</td>\n",
       "      <td>5392.18363</td>\n",
       "      <td>0.99974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 MSE         RMSE       R2\n",
       "Linear Regression   4328005232.18433  65787.57658  0.96163\n",
       "Decision Tree         77004555.55556   8775.22396  0.99932\n",
       "Random Forest         75306351.56509   8677.92323  0.99933\n",
       "SVR               118773156180.84033 344634.81568 -0.05308\n",
       "XGBoost               29075644.35328   5392.18363  0.99974"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set list and index names\n",
    "dict_list = [LR_metrics, DTree_metrics, Forest_metrics, SVR_metrics, XGB_metrics]\n",
    "index_names = ['Linear Regression', 'Decision Tree', 'Random Forest', 'SVR', 'XGBoost']\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "\n",
    "metricsDF = pd.DataFrame(dict_list, index=index_names)\n",
    "metricsDF['RMSE'] = metricsDF['MSE']**0.5\n",
    "\n",
    "metricsDF[['MSE', 'RMSE', 'R2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection Results\n",
    "The two scoring metrics we will focus on are RMSE and R2. <br>\n",
    "Using RMSE will show us an error on the same scale as our expected sale prices and will allow us to compare the different models. <br>\n",
    "R2 will give us an idea of how accurate the model predictions are with the actual sold price from our test data. <br>\n",
    "\n",
    "* We can see that the XGBoost gives use the lowest RMSE, so we should select that model.\n",
    "* The next best model is the decision tree and the random forest models. Given that random forest shows slightly better metrics and builds off of many decision trees, we will use that\n",
    "    * Using the default parameters for the decision tree and random forest models, we see that the predicted results have no error. We can determine that the max depth of the tree accounts for all variability from the data.\n",
    "    * In our case, the model predicts the test data accurately, but there may be overfitting. It may be worth setting the parameters to limit the max depth of the tree, limiting parameters, or folding the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection - STRETCH\n",
    "\n",
    "> **This step doesn't need to be part of your Minimum Viable Product (MVP), but its recommended you complete it if you have time!**\n",
    "\n",
    "Even with all the preprocessing we did in Notebook 1, you probably still have a lot of features. Are they all important for prediction?\n",
    "\n",
    "Investigate some feature selection algorithms (Lasso, RFE, Forward/Backward Selection)\n",
    "- Perform feature selection to get a reduced subset of your original features\n",
    "- Refit your models with this reduced dimensionality - how does performance change on your chosen metrics?\n",
    "- Based on this, should you include feature selection in your final pipeline? Explain\n",
    "\n",
    "Remember, feature selection often doesn't directly improve performance, but if performance remains the same, a simpler model is often preferrable. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform feature selection \n",
    "# refit models\n",
    "# gather evaluation metrics and compare to the previous step (full feature set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
