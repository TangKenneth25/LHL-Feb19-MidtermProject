{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "This notebook should include preliminary and baseline modeling.\n",
    "- Try as many different models as possible.\n",
    "- Don't worry about hyperparameter tuning or cross validation here.\n",
    "- Ideas include:\n",
    "    - linear regression\n",
    "    - support vector machines\n",
    "    - random forest\n",
    "    - xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import models and fit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.200000e+03</td>\n",
       "      <td>5.200000e+03</td>\n",
       "      <td>5.200000e+03</td>\n",
       "      <td>5.200000e+03</td>\n",
       "      <td>5.200000e+03</td>\n",
       "      <td>5.200000e+03</td>\n",
       "      <td>5.200000e+03</td>\n",
       "      <td>5.200000e+03</td>\n",
       "      <td>5.200000e+03</td>\n",
       "      <td>5.200000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>5.200000e+03</td>\n",
       "      <td>5.200000e+03</td>\n",
       "      <td>5.200000e+03</td>\n",
       "      <td>5.200000e+03</td>\n",
       "      <td>5.200000e+03</td>\n",
       "      <td>5.200000e+03</td>\n",
       "      <td>5.200000e+03</td>\n",
       "      <td>5.200000e+03</td>\n",
       "      <td>5.200000e+03</td>\n",
       "      <td>5.200000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.155070e-17</td>\n",
       "      <td>-3.411972e-15</td>\n",
       "      <td>-4.561138e-15</td>\n",
       "      <td>3.279428e-17</td>\n",
       "      <td>-5.334536e-15</td>\n",
       "      <td>4.645856e-17</td>\n",
       "      <td>-8.198570e-18</td>\n",
       "      <td>1.222953e-16</td>\n",
       "      <td>-1.667043e-16</td>\n",
       "      <td>4.235928e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>8.642659e-17</td>\n",
       "      <td>4.372571e-17</td>\n",
       "      <td>9.155070e-17</td>\n",
       "      <td>5.192428e-17</td>\n",
       "      <td>1.298107e-17</td>\n",
       "      <td>4.372571e-17</td>\n",
       "      <td>-6.148928e-18</td>\n",
       "      <td>1.981321e-17</td>\n",
       "      <td>6.558856e-17</td>\n",
       "      <td>-2.186285e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000096e+00</td>\n",
       "      <td>1.000096e+00</td>\n",
       "      <td>1.000096e+00</td>\n",
       "      <td>1.000096e+00</td>\n",
       "      <td>1.000096e+00</td>\n",
       "      <td>1.000096e+00</td>\n",
       "      <td>1.000096e+00</td>\n",
       "      <td>1.000096e+00</td>\n",
       "      <td>1.000096e+00</td>\n",
       "      <td>1.000096e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000096e+00</td>\n",
       "      <td>1.000096e+00</td>\n",
       "      <td>1.000096e+00</td>\n",
       "      <td>1.000096e+00</td>\n",
       "      <td>1.000096e+00</td>\n",
       "      <td>1.000096e+00</td>\n",
       "      <td>1.000096e+00</td>\n",
       "      <td>1.000096e+00</td>\n",
       "      <td>1.000096e+00</td>\n",
       "      <td>1.000096e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.619049e+00</td>\n",
       "      <td>-2.396421e+01</td>\n",
       "      <td>-3.967251e+00</td>\n",
       "      <td>-2.327678e-01</td>\n",
       "      <td>-3.820993e+00</td>\n",
       "      <td>-5.964761e-01</td>\n",
       "      <td>-3.902324e-01</td>\n",
       "      <td>-1.863974e+00</td>\n",
       "      <td>-1.820466e+00</td>\n",
       "      <td>-8.570274e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.076163e+00</td>\n",
       "      <td>-5.378625e-02</td>\n",
       "      <td>-8.914750e-02</td>\n",
       "      <td>-3.286841e-01</td>\n",
       "      <td>-1.958026e-01</td>\n",
       "      <td>-1.476880e-01</td>\n",
       "      <td>-2.875007e-01</td>\n",
       "      <td>-2.402615e-02</td>\n",
       "      <td>-1.464853e+00</td>\n",
       "      <td>-2.835617e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-9.351284e-01</td>\n",
       "      <td>-2.685789e-01</td>\n",
       "      <td>-6.187975e-01</td>\n",
       "      <td>-2.327678e-01</td>\n",
       "      <td>1.275023e-02</td>\n",
       "      <td>-5.964761e-01</td>\n",
       "      <td>-2.781443e-01</td>\n",
       "      <td>-6.531968e-01</td>\n",
       "      <td>-9.536568e-01</td>\n",
       "      <td>-8.570274e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.250803e-01</td>\n",
       "      <td>-5.378625e-02</td>\n",
       "      <td>-8.914750e-02</td>\n",
       "      <td>-3.286841e-01</td>\n",
       "      <td>-1.958026e-01</td>\n",
       "      <td>-1.476880e-01</td>\n",
       "      <td>-2.875007e-01</td>\n",
       "      <td>-2.402615e-02</td>\n",
       "      <td>-1.464853e+00</td>\n",
       "      <td>-2.835617e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-4.968707e-02</td>\n",
       "      <td>2.194405e-01</td>\n",
       "      <td>1.545751e-01</td>\n",
       "      <td>-2.327678e-01</td>\n",
       "      <td>3.886074e-01</td>\n",
       "      <td>-5.964761e-01</td>\n",
       "      <td>-2.184802e-01</td>\n",
       "      <td>-2.397351e-01</td>\n",
       "      <td>-8.684762e-02</td>\n",
       "      <td>3.641291e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>3.250803e-01</td>\n",
       "      <td>-5.378625e-02</td>\n",
       "      <td>-8.914750e-02</td>\n",
       "      <td>-3.286841e-01</td>\n",
       "      <td>-1.958026e-01</td>\n",
       "      <td>-1.476880e-01</td>\n",
       "      <td>-2.875007e-01</td>\n",
       "      <td>-2.402615e-02</td>\n",
       "      <td>6.826622e-01</td>\n",
       "      <td>-2.835617e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.660643e-01</td>\n",
       "      <td>5.084780e-01</td>\n",
       "      <td>7.842986e-01</td>\n",
       "      <td>-2.327678e-01</td>\n",
       "      <td>5.389502e-01</td>\n",
       "      <td>1.265274e+00</td>\n",
       "      <td>-1.147660e-01</td>\n",
       "      <td>3.270565e-01</td>\n",
       "      <td>7.799616e-01</td>\n",
       "      <td>8.643100e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.250803e-01</td>\n",
       "      <td>-5.378625e-02</td>\n",
       "      <td>-8.914750e-02</td>\n",
       "      <td>-3.286841e-01</td>\n",
       "      <td>-1.958026e-01</td>\n",
       "      <td>-1.476880e-01</td>\n",
       "      <td>-2.875007e-01</td>\n",
       "      <td>-2.402615e-02</td>\n",
       "      <td>6.826622e-01</td>\n",
       "      <td>-2.835617e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.721196e+00</td>\n",
       "      <td>1.139273e+00</td>\n",
       "      <td>1.614389e+00</td>\n",
       "      <td>6.104366e+00</td>\n",
       "      <td>6.892931e-01</td>\n",
       "      <td>8.712275e+00</td>\n",
       "      <td>1.575831e+01</td>\n",
       "      <td>6.479283e+00</td>\n",
       "      <td>5.114008e+00</td>\n",
       "      <td>8.610328e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.250803e-01</td>\n",
       "      <td>1.859211e+01</td>\n",
       "      <td>1.121736e+01</td>\n",
       "      <td>3.042435e+00</td>\n",
       "      <td>5.107184e+00</td>\n",
       "      <td>6.771030e+00</td>\n",
       "      <td>3.478252e+00</td>\n",
       "      <td>4.162131e+01</td>\n",
       "      <td>6.826622e-01</td>\n",
       "      <td>3.526570e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1             2             3             4  \\\n",
       "count  5.200000e+03  5.200000e+03  5.200000e+03  5.200000e+03  5.200000e+03   \n",
       "mean   9.155070e-17 -3.411972e-15 -4.561138e-15  3.279428e-17 -5.334536e-15   \n",
       "std    1.000096e+00  1.000096e+00  1.000096e+00  1.000096e+00  1.000096e+00   \n",
       "min   -1.619049e+00 -2.396421e+01 -3.967251e+00 -2.327678e-01 -3.820993e+00   \n",
       "25%   -9.351284e-01 -2.685789e-01 -6.187975e-01 -2.327678e-01  1.275023e-02   \n",
       "50%   -4.968707e-02  2.194405e-01  1.545751e-01 -2.327678e-01  3.886074e-01   \n",
       "75%    8.660643e-01  5.084780e-01  7.842986e-01 -2.327678e-01  5.389502e-01   \n",
       "max    1.721196e+00  1.139273e+00  1.614389e+00  6.104366e+00  6.892931e-01   \n",
       "\n",
       "                  5             6             7             8             9  \\\n",
       "count  5.200000e+03  5.200000e+03  5.200000e+03  5.200000e+03  5.200000e+03   \n",
       "mean   4.645856e-17 -8.198570e-18  1.222953e-16 -1.667043e-16  4.235928e-17   \n",
       "std    1.000096e+00  1.000096e+00  1.000096e+00  1.000096e+00  1.000096e+00   \n",
       "min   -5.964761e-01 -3.902324e-01 -1.863974e+00 -1.820466e+00 -8.570274e-01   \n",
       "25%   -5.964761e-01 -2.781443e-01 -6.531968e-01 -9.536568e-01 -8.570274e-01   \n",
       "50%   -5.964761e-01 -2.184802e-01 -2.397351e-01 -8.684762e-02  3.641291e-03   \n",
       "75%    1.265274e+00 -1.147660e-01  3.270565e-01  7.799616e-01  8.643100e-01   \n",
       "max    8.712275e+00  1.575831e+01  6.479283e+00  5.114008e+00  8.610328e+00   \n",
       "\n",
       "       ...            36            37            38            39  \\\n",
       "count  ...  5.200000e+03  5.200000e+03  5.200000e+03  5.200000e+03   \n",
       "mean   ...  8.642659e-17  4.372571e-17  9.155070e-17  5.192428e-17   \n",
       "std    ...  1.000096e+00  1.000096e+00  1.000096e+00  1.000096e+00   \n",
       "min    ... -3.076163e+00 -5.378625e-02 -8.914750e-02 -3.286841e-01   \n",
       "25%    ...  3.250803e-01 -5.378625e-02 -8.914750e-02 -3.286841e-01   \n",
       "50%    ...  3.250803e-01 -5.378625e-02 -8.914750e-02 -3.286841e-01   \n",
       "75%    ...  3.250803e-01 -5.378625e-02 -8.914750e-02 -3.286841e-01   \n",
       "max    ...  3.250803e-01  1.859211e+01  1.121736e+01  3.042435e+00   \n",
       "\n",
       "                 40            41            42            43            44  \\\n",
       "count  5.200000e+03  5.200000e+03  5.200000e+03  5.200000e+03  5.200000e+03   \n",
       "mean   1.298107e-17  4.372571e-17 -6.148928e-18  1.981321e-17  6.558856e-17   \n",
       "std    1.000096e+00  1.000096e+00  1.000096e+00  1.000096e+00  1.000096e+00   \n",
       "min   -1.958026e-01 -1.476880e-01 -2.875007e-01 -2.402615e-02 -1.464853e+00   \n",
       "25%   -1.958026e-01 -1.476880e-01 -2.875007e-01 -2.402615e-02 -1.464853e+00   \n",
       "50%   -1.958026e-01 -1.476880e-01 -2.875007e-01 -2.402615e-02  6.826622e-01   \n",
       "75%   -1.958026e-01 -1.476880e-01 -2.875007e-01 -2.402615e-02  6.826622e-01   \n",
       "max    5.107184e+00  6.771030e+00  3.478252e+00  4.162131e+01  6.826622e-01   \n",
       "\n",
       "                 45  \n",
       "count  5.200000e+03  \n",
       "mean  -2.186285e-17  \n",
       "std    1.000096e+00  \n",
       "min   -2.835617e-01  \n",
       "25%   -2.835617e-01  \n",
       "50%   -2.835617e-01  \n",
       "75%   -2.835617e-01  \n",
       "max    3.526570e+00  \n",
       "\n",
       "[8 rows x 46 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "X_train_scaled = pd.read_csv('../data/processed/X_train_scaled.csv')\n",
    "X_test_scaled = pd.read_csv('../data/processed/X_test_scaled.csv')\n",
    "y_train = pd.read_csv('../data/processed/y_train.csv')\n",
    "y_test = pd.read_csv('../data/processed/y_test.csv')\n",
    "\n",
    "X_train_scaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: \t 3890321884.3568015\n",
      "Test MSE: \t 4146077707.644794\n",
      "Train R2: \t 0.9630973918376792\n",
      "Test R2: \t 0.9593341086570428\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "LR_model = LinearRegression()\n",
    "LR_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_train_LR = LR_model.predict(X_train_scaled)\n",
    "y_test_LR = LR_model.predict(X_test_scaled)\n",
    "\n",
    "train_mse_LR = mean_squared_error(y_train, y_train_LR)\n",
    "train_r2_LR = r2_score(y_train, y_train_LR)\n",
    "\n",
    "mse_LR = mean_squared_error(y_test, y_test_LR)\n",
    "r2_LR = r2_score(y_test, y_test_LR)\n",
    "\n",
    "LR_metrics = {'MSE':mse_LR, 'R2':r2_LR}\n",
    "\n",
    "print(f'Train MSE: \\t {train_mse_LR}')\n",
    "print(f'Test MSE: \\t {mse_LR}')\n",
    "print(f'Train R2: \\t {train_r2_LR}')\n",
    "print(f'Test R2: \\t {r2_LR}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: \t 0.0\n",
      "Test MSE: \t 21375707.0\n",
      "Train R2: \t 1.0\n",
      "Test R2: \t 0.9997903410790786\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "tree_model = DecisionTreeRegressor(random_state=42)\n",
    "tree_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_train_tree = tree_model.predict(X_train_scaled)\n",
    "y_test_tree = tree_model.predict(X_test_scaled)\n",
    "\n",
    "train_mse_tree = mean_squared_error(y_train, y_train_tree)\n",
    "train_r2_tree = r2_score(y_train, y_train_tree)\n",
    "\n",
    "mse_tree = mean_squared_error(y_test, y_test_tree)\n",
    "r2_tree = r2_score(y_test, y_test_tree)\n",
    "\n",
    "DTree_metrics = {'MSE':mse_tree, 'R2':r2_tree}\n",
    "\n",
    "print(f'Train MSE: \\t {train_mse_tree}')\n",
    "print(f'Test MSE: \\t {mse_tree}')\n",
    "print(f'Train R2: \\t {train_r2_tree}')\n",
    "print(f'Test R2: \\t {r2_tree}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kool3\\anaconda3\\envs\\Lighthouse\\lib\\site-packages\\sklearn\\base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: \t 12319780.788696423\n",
      "Test MSE: \t 43155462.35645008\n",
      "Train R2: \t 0.9998831376794504\n",
      "Test R2: \t 0.9995767191387159\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "forest_model = RandomForestRegressor(random_state=42)\n",
    "forest_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_train_forest = forest_model.predict(X_train_scaled)\n",
    "y_test_forest = forest_model.predict(X_test_scaled)\n",
    "\n",
    "train_mse_forest = mean_squared_error(y_train, y_train_forest)\n",
    "train_r2_forest = r2_score(y_train, y_train_forest)\n",
    "\n",
    "mse_forest = mean_squared_error(y_test, y_test_forest)\n",
    "r2_forest = r2_score(y_test, y_test_forest)\n",
    "\n",
    "Forest_metrics = {'MSE':mse_forest, 'R2':r2_forest}\n",
    "\n",
    "print(f'Train MSE: \\t {train_mse_forest}')\n",
    "print(f'Test MSE: \\t {mse_forest}')\n",
    "print(f'Train R2: \\t {train_r2_forest}')\n",
    "print(f'Test R2: \\t {r2_forest}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kool3\\anaconda3\\envs\\Lighthouse\\lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: \t 110270549438.92082\n",
      "Test MSE: \t 106861159273.6704\n",
      "Train R2: \t 1.0\n",
      "Test R2: \t -0.04812417861653273\n"
     ]
    }
   ],
   "source": [
    "# SVR\n",
    "svr_model = SVR(kernel='rbf')\n",
    "svr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_train_svr = svr_model.predict(X_train_scaled)\n",
    "y_test_svr = svr_model.predict(X_test_scaled)\n",
    "\n",
    "train_mse_svr = mean_squared_error(y_train, y_train_svr)\n",
    "train_r2_svr = r2_score(y_train, y_train_tree)\n",
    "\n",
    "mse_svr = mean_squared_error(y_test, y_test_svr)\n",
    "r2_svr = r2_score(y_test, y_test_svr)\n",
    "\n",
    "SVR_metrics = {'MSE':mse_svr, 'R2':r2_svr}\n",
    "\n",
    "print(f'Train MSE: \\t {train_mse_svr}')\n",
    "print(f'Test MSE: \\t {mse_svr}')\n",
    "print(f'Train R2: \\t {train_r2_svr}')\n",
    "print(f'Test R2: \\t {r2_svr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: \t 3852866.4934079964\n",
      "Test MSE: \t 40015271.04752819\n",
      "Train R2: \t 0.9999634526841905\n",
      "Test R2: \t 0.999607519014543\n"
     ]
    }
   ],
   "source": [
    "# XGBoots\n",
    "xgb_model = XGBRegressor(random_state=42)\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_train_xgb = xgb_model.predict(X_train_scaled)\n",
    "y_test_xgb = xgb_model.predict(X_test_scaled)\n",
    "\n",
    "train_mse_xgb = mean_squared_error(y_train, y_train_xgb)\n",
    "train_r2_xgb = r2_score(y_train, y_train_xgb)\n",
    "\n",
    "mse_xgb = mean_squared_error(y_test, y_test_xgb)\n",
    "r2_xgb = r2_score(y_test, y_test_xgb)\n",
    "\n",
    "XGB_metrics = {'MSE':mse_xgb, 'R2':r2_xgb}\n",
    "\n",
    "print(f'Train MSE: \\t {train_mse_xgb}')\n",
    "print(f'Test MSE: \\t {mse_xgb}')\n",
    "print(f'Train R2: \\t {train_r2_xgb}')\n",
    "print(f'Test R2: \\t {r2_xgb}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider what metrics you want to use to evaluate success.\n",
    "- If you think about mean squared error, can we actually relate to the amount of error?\n",
    "- Try root mean squared error so that error is closer to the original units (dollars)\n",
    "- What does RMSE do to outliers?\n",
    "- Is mean absolute error a good metric for this problem?\n",
    "- What about R^2? Adjusted R^2?\n",
    "- Briefly describe your reasons for picking the metrics you use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>4146077707.64479</td>\n",
       "      <td>64390.04354</td>\n",
       "      <td>0.95933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>21375707.00000</td>\n",
       "      <td>4623.38696</td>\n",
       "      <td>0.99979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>43155462.35645</td>\n",
       "      <td>6569.28172</td>\n",
       "      <td>0.99958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>106861159273.67039</td>\n",
       "      <td>326896.25154</td>\n",
       "      <td>-0.04812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>40015271.04753</td>\n",
       "      <td>6325.76249</td>\n",
       "      <td>0.99961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 MSE         RMSE       R2\n",
       "Linear Regression   4146077707.64479  64390.04354  0.95933\n",
       "Decision Tree         21375707.00000   4623.38696  0.99979\n",
       "Random Forest         43155462.35645   6569.28172  0.99958\n",
       "SVR               106861159273.67039 326896.25154 -0.04812\n",
       "XGBoost               40015271.04753   6325.76249  0.99961"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set list and index names\n",
    "dict_list = [LR_metrics, DTree_metrics, Forest_metrics, SVR_metrics, XGB_metrics]\n",
    "index_names = ['Linear Regression', 'Decision Tree', 'Random Forest', 'SVR', 'XGBoost']\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "\n",
    "metricsDF = pd.DataFrame(dict_list, index=index_names)\n",
    "metricsDF['RMSE'] = metricsDF['MSE']**0.5\n",
    "\n",
    "metricsDF[['MSE', 'RMSE', 'R2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection Results\n",
    "The two scoring metrics we will focus on are RMSE and R2. <br>\n",
    "Using RMSE will show us an error on the same scale as our expected sale prices and will allow us to compare the different models. <br>\n",
    "R2 will give us an idea of how accurate the model predictions are with the actual sold price from our test data. <br>\n",
    "\n",
    "* We can see that the XGBoost gives use the lowest RMSE, so we should select that model.\n",
    "* The next best model is the decision tree and the random forest models. Given that random forest shows slightly better metrics and builds off of many decision trees, we will use that\n",
    "    * Using the default parameters for the decision tree and random forest models, we see that the predicted results have no error. We can determine that the max depth of the tree accounts for all variability from the data.\n",
    "    * In our case, the model predicts the test data accurately, but there may be overfitting. It may be worth setting the parameters to limit the max depth of the tree, limiting parameters, or folding the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection - STRETCH\n",
    "\n",
    "> **This step doesn't need to be part of your Minimum Viable Product (MVP), but its recommended you complete it if you have time!**\n",
    "\n",
    "Even with all the preprocessing we did in Notebook 1, you probably still have a lot of features. Are they all important for prediction?\n",
    "\n",
    "Investigate some feature selection algorithms (Lasso, RFE, Forward/Backward Selection)\n",
    "- Perform feature selection to get a reduced subset of your original features\n",
    "- Refit your models with this reduced dimensionality - how does performance change on your chosen metrics?\n",
    "- Based on this, should you include feature selection in your final pipeline? Explain\n",
    "\n",
    "Remember, feature selection often doesn't directly improve performance, but if performance remains the same, a simpler model is often preferrable. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform feature selection \n",
    "# refit models\n",
    "# gather evaluation metrics and compare to the previous step (full feature set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
